{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание\n",
    "\n",
    "Натренируйти нейронные сети различных архитектур на *fashion-mnist*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Loading FMNIST...\n",
      "└ @ Main C:\\Users\\User\\.julia\\packages\\Knet\\T1oum\\data\\fashion-mnist.jl:37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubString{String}[\"T-shirt/top\", \"Shirt\", \"Shirt\"]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAQESURBVGje7drNa1xVGMfxT5KZaSdpGlvTN19jC7WiYN21BQU3FbrQjajgyp1/grgTwb9A/wCXdiuIS1d14cIiCFILKthWW1tjbdpOXmZc/M5lEmaadCGZ4ZIDQ2buPfc89znf/J7nOefeCQ/R3sZZNHEZl9DBq3gGh/AFPsP9LcaafBiD/2erv8GJB52Yxkc4jSU8htv4A3fKhc/hCP7C7tLnB7yL38bFw/obfCDDr/APboq2TuIwrmOqHPsX+9DDFTyKWeH/puEc6z+l48HwfbwgnGYlbvbwCuZxDWvYg1v4FS1h18OT2FXGGLmH9TfYGHbwLH4qJ+8Jnxa+wUGJn/C7aLUp/ww9tLEsrM/gwqg9rL/BAYanhdcM/hRmU6K7fZILL4tG50SLy+XOG5IXJ9HFB3h91B7W3+AAw3O4KnxIzrtU7my/xMiWMOpgsfQ7JRokMfWW5M+Re1h/gxsYzovW7klsnBeGHayWPouiy0a529s4LrqdLsdWhfM8PsGHo/Sw/gY3MHxD9Ncpv5dEd02JqbNSe94RTs1yrCv8mnii/P4en+LzUXtYf4MDdekZyWEv4yjOC8u/hVGv/G6JRudknfh86XMVX8uafyw8rL/BgXx4oXzawvBc+fuLaHFGaphdElerWrQhbN9bN1ZVq47Uw/ob3MCwEmVPcuKPeE3i5KLUKF19hsul35p+Pbq+9YYYrP+UjpbhsDmfFX3txgFheEN4T8t6fqpcOz2OHtbfYGOrDm3hc1dqnb2iwSon3it3vWLjfvewODoSD+tv8KEZHpF1x5TUMVUsvVv6dMr5sfOw/ga3ZDgn+2lXheNd/Fy+TwnHCdHg3nXX7ehw29pQhuvn/xHhd7B8mhJHZySOLkke7JbBTuJiGWOnLt2WtinDhmjruuiveu50Q5g1RYcdYUr2bC6Ok4f1NziUYaWdZ/VzYRsvSe1S7d+Q/ZpJ4b6KE+X42rh4WH+Dm+rwqOzFtKUG3Se6W9CvSfeX4/fLNafGzcP6GxzKsFv+ntCPlV3R1pr+vjbhu1QGWsWxcfOw/gY3rUuPS03akzV+S/a7WxJTVyQPVs8Ol8v5Q/Lscaem2ZY2wHD9vM/J+06N8pmQOma3xM6G5MUq961IDXRUGE4azIv1n9LRM6zmfY+sK67pv4vRLOfb8tyQvib36NeyL+LbcfGw/gaH6pDUKVckD64Iv65wWpPcV2mxI7UPib0HyvdhtWn9p3T0DKs7WMDjwm8VT0kMbeuv8w9L7qv2xDul31l8bCcfblMbeAZcvc8EX0qd2ZLceF3y30zpU+2xLUg9Q55XvSP7cdW7VCP1sP4GJ7bq8DTekn22Y8LrlqwNp8sAN+Ud0/P4btw8rL/B/wCyB+BPoOW0GAAAAABJRU5ErkJggg==",
      "text/plain": [
       "28×28 reinterpret(Gray{Float32}, ::Array{Float32,2}):\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " ⋮                                       ⋱                    \n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAP5SURBVGje7dpNiBxFFAfw32Q22V3jmv0gamJEiAriJyJ48eOgiBcvXgSPBhT17EERvXvwIOjNi1cVRAVFiN4UDepBQYzkoOA3JmqibJzd2fHwqrZrembX02wv7TwYuqa6ql+/+vN/9d6r7qhJB4Na3334EL/bWu5PY34t+rro18btscPSfoWduvaN1L4Fx3ADFnEIb+NFfJ7G3IjHcW0a91HqfwVvYG03WNh+hZ2ykfn3Ms7iCrwm8HsUR3ABTqKHWZzCxYJ/T+ERXI7v8BaO157d/iXdcYUz9Y4nxfp/g9cFB69KA09hAUv4Ml2XBYY9XIoPcAbX43Z8je/T/PUmLGy/wiFfeg/uxbdiH1vDJXgstf8RvnYJz+EZwdfzqe+E4O0MVjCPo3ioSQvbr3CIh3cJPPpYxUGBaVdwaybdO4j9+FNgO8BfuFvw9zfhb6/DH+kZ7zVlYfsVbvLwebH/fYVzIqb5GM/iF+EH5wWGfRzGz8WD+oJ7x4XPPSJwPCr88RP4oQkL269wE8Nbha98WOx1q7hDcOhvVUwyELFMX+CaiZwxhpfwE24WOL+bxp9swsL2K9z0pSfSdU3sXy/gagHyeYFPjklyztAt3nomjbtQ4HWT8M3HBLcbs7D9Cjd5mOPGZTwoMHtAxJo5ltmTfoP0y5O76X+Obd4Use0nIk7tpHn9/8WSNhuX1uW0wPWsCr+c62UMOwKbWeFzL8PTgse7wsL2KxzJD8tazRei/rIuMMocLN809+WaWg+vpva84PDANMefoIxguFG0F8XaZ1zz4NIn9lUYbQi/uiBiml7teY1Y2H6FM9vdPCA4yH84XZWP7eCibea0f0l3F4ZnRJ0m74MZk+2w6Yic8FOj5x+NWNh+hSMYlvXpOcM4bMfFEt+V1J5iuCMyNqbJ8cl+lS/N+13HMCcZxm9d1GjynNw/jWkmJltiuCDOmU6LmLTEo5ScW2wUc68s7pUxaSMWtl/hWAyJeug+gc1eUZsZx8EsOSbtqTDMMemUhxOVsfshkVeU+WB5jyoGzblHfvs1o99sTDGcqIxg2EvXO1X7Yt8wB8v9r6PiW8ZwufbMMkds/5I2j2Hmy+HU7hb3SuzKWlvJxYGIhUqLphhOVLbE8IBRDEv/WY6l4uNA7J/5m7YphhOXLXP8JdVZUz0mHcdDqvxjVtRqxn3L2P4l3T0Y7lXlDftS38aYa9cwpvWaTleVYzZiYfsVbonhjyoM19J1zvD5IZX/zL503TBu05r3xGVmXMc6rhHxZcZrRRV3rho+z6A6719I7UVx7livt7V/SZs/A864HMRt4lvuQ6Jms6I6R5wTPjbXZs4J/n2G9/FO7XmNWdh+hf8C7TH0DEmENNMAAAAASUVORK5CYII=",
      "text/plain": [
       "28×28 reinterpret(Gray{Float32}, ::Array{Float32,2}):\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " ⋮                                       ⋱                    \n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAANsSURBVGje7ZrNahRBEIC/2Z/JJruoqBgxCGoEEU+ieFBBPIoiHjyIePEV1FMuIr6ENxEE30AJ3kSPAQ9eFUEvCYgaN5vo/oyH6mJqZ3s3l2xmaKZg2Nmenq6p+ajqqu6JmCAVYMDOSmWHxysVEm3X4TCwBFwEFoFl4AOwBiwAJ4FzQAv4DjwF3hfJwvAVjjC0vncVeOnatoB/QAOoA3+AJtADum6gGaAGPEe4F8LC8BVGvobEnX9COK27J6sAfYRxxfTX8777fwS4ifirHS8XC8NXONYPl4BHwCpQRTiofyaem5VlD4mr34BLRbAwfIVj58PPSMzsIlxsbpNkbtRrVWdBBOwFrgEreVsYvsKarzFGeAyQOa7rznuuPULipp07tV2514HblAx3QbwM7wH7gA7CYsM92QzCSec4nR8x7RWEZx+4XAQLw1foZXjL/cZA23VSLhorNa+puXaNr4m77y9wvggWhq/QOx+uIizmgJ+k8dIyVEkYzTsbSB0yC1wAvuZpYfgKR/zwGLCJcGq6NvUvjZcqNj8dkMbSxFy/DzzO08LwFY4wPEOaX8aITylT5WdrvmyOauNsFbhOyXDK4o2lJ4DXwCmkzp9H8hr7hIk5tC7U3PQQEkdfAXfztjB8hduul34EjgI/kBxVHXdgfmuka24HgBfAg6JYGL5Cb16qOSjAaSSvUR9TsXOk+qLmM28yfXK1MHyFXoZ2TSZmOJ9RjpafffIEuAK8pWS4SzLWD3vu/AviW5DOf+qTPXOPrf33mHGy+4/hv9JiMMx2sDU8jK55R5mj5dp9+8fhv9JiMFRGB5H8csNzzfqdZdkH9rv/fc/Y4b/SYjBUJmddBxs/NXdRXhHDazcDZM+iMBaGr3BiLF1keO8wm5vi+d8Djmeul3vAU5WJDDsIuwSpDRNPH7teU0HWujvmeslw6jJxPqwznMdUM9ez9aLG1zjTnquF4Suc6Iez7jfJHHX3pF3TV/mpFQ3kO6rcLQxfoZdhHeHRRnxvizSWxqRr2lojqn/23YBdUn5lfTh18a6X2rW2FWQ/6jeyF9UCfiHsGsge46Y7YqS+fwg8K4qF4Sv0+qGt624g30etIXXfHJK3rCNMm6TrOvPAE1J+vu/Ew3+lxfBDn9xB9uS1fl9A2LYRpsvAO8/g5Xrp1OU/ufC6LNwdMugAAAAASUVORK5CYII=",
      "text/plain": [
       "28×28 reinterpret(Gray{Float32}, ::Array{Float32,2}):\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " ⋮                                       ⋱                    \n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)  …  Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)\n",
       " Gray{Float32}(0.0)  Gray{Float32}(0.0)     Gray{Float32}(0.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Взгляните на некоторые случайные изображения и метки в данных\n",
    "using Pkg; for p in (\"Knet\",\"Images\",\"ImageMagick\"); haskey(Pkg.installed(),p) || Pkg.add(p); end\n",
    "using Knet,Images,Random\n",
    "\n",
    "include(Knet.dir(\"data\",\"fashion-mnist.jl\"))\n",
    "xtrn,ytrn,xtst,ytst,lbls = fmnist()\n",
    "rp = randperm(10000)\n",
    "println(lbls[ytst[rp[1:3]]]); flush(stdout)\n",
    "\n",
    "for i=1:3\n",
    "    display(fmnistview(xtst,rp[i]))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Main.FashionMNIST"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"fashion-mnist.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This example learns to classify images of fashion products(trousers, shirts, bags...)  from the [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset.   There are 60000 training and 10000 test examples. Each input x  consists of 784 pixels representing a 28x28 image. The pixel values are  normalized to [0,1]. Each output y is converted to a ten-dimensional  one-hot vector (a vector that has a single non-zero component) indicating  the correct class (0-9) for a given image. 10 is used instead of 0. Labels and descriptions are shown below.\n",
       "\n",
       "```\n",
       "Label   Description\n",
       "1       T-shirt/top\n",
       "2       Trouser\n",
       "3       Pullover\n",
       "4       Dress\n",
       "5       Coat\n",
       "6       Sandal\n",
       "7       Shirt\n",
       "8       Sneaker\n",
       "9       Bag\n",
       "10      Ankle boot\n",
       "```\n",
       "\n",
       "You can run the demo using `julia fashion-mnist.jl` on the command line or by first including `julia> include(\"fashion-mnist.jl\")` and typing `julia> FashionMNIST.main()`  at the Julia prompt.  Options can be used like `julia fashion-mnist.jl --epochs 3`  or `julia> FashionMNIST.main(\"--epochs 3\")`. Use `julia fashion-mnist.jl --help`  for a list of options.  The dataset will be automatically downloaded.   By default a softmax model will be trained for 10 epochs. You can also  train a multi-layer perceptron by specifying one or more –hidden sizes.  The accuracy for the training and test sets will be printed at every epoch  and optimized parameters will be returned.\n"
      ],
      "text/plain": [
       "  This example learns to classify images of fashion products(trousers, shirts, bags...) from the Fashion-MNIST\n",
       "  (https://github.com/zalandoresearch/fashion-mnist) dataset. There are 60000 training and 10000 test examples. Each input x consists of 784 pixels\n",
       "  representing a 28x28 image. The pixel values are normalized to [0,1]. Each output y is converted to a ten-dimensional one-hot vector (a vector that\n",
       "  has a single non-zero component) indicating the correct class (0-9) for a given image. 10 is used instead of 0. Labels and descriptions are shown\n",
       "  below.\n",
       "\n",
       "\u001b[36m  Label   Description\u001b[39m\n",
       "\u001b[36m  1       T-shirt/top\u001b[39m\n",
       "\u001b[36m  2       Trouser\u001b[39m\n",
       "\u001b[36m  3       Pullover\u001b[39m\n",
       "\u001b[36m  4       Dress\u001b[39m\n",
       "\u001b[36m  5       Coat\u001b[39m\n",
       "\u001b[36m  6       Sandal\u001b[39m\n",
       "\u001b[36m  7       Shirt\u001b[39m\n",
       "\u001b[36m  8       Sneaker\u001b[39m\n",
       "\u001b[36m  9       Bag\u001b[39m\n",
       "\u001b[36m  10      Ankle boot\u001b[39m\n",
       "\n",
       "  You can run the demo using \u001b[36mjulia fashion-mnist.jl\u001b[39m on the command line or by first including \u001b[36mjulia> include(\"fashion-mnist.jl\")\u001b[39m and typing \u001b[36mjulia>\n",
       "  FashionMNIST.main()\u001b[39m at the Julia prompt. Options can be used like \u001b[36mjulia fashion-mnist.jl --epochs 3\u001b[39m or \u001b[36mjulia> FashionMNIST.main(\"--epochs 3\")\u001b[39m. Use\n",
       "  \u001b[36mjulia fashion-mnist.jl --help\u001b[39m for a list of options. The dataset will be automatically downloaded. By default a softmax model will be trained for\n",
       "  10 epochs. You can also train a multi-layer perceptron by specifying one or more –hidden sizes. The accuracy for the training and test sets will be\n",
       "  printed at every epoch and optimized parameters will be returned."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@doc FashionMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: <PROGRAM> [--seed SEED] [--batchsize BATCHSIZE]\n",
      "                 [--epochs EPOCHS] [--hidden [HIDDEN...]] [--lr LR]\n",
      "                 [--winit WINIT] [--fast] [--atype ATYPE]\n",
      "                 [--gcheck GCHECK] [--dropout DROPOUT]\n",
      "\n",
      "fashion-mnist.jl (c) 2017 Adapted by Emre Unal based on Deniz Yuret’s\n",
      "MNIST example\n",
      "https://github.com/denizyuret/Knet.jl/tree/master/examples/mnist-mlp/mlp.jl.\n",
      "Multi-layer perceptron model on the Fashion-MNIST dataset from\n",
      "https://github.com/zalandoresearch/fashion-mnist.\n",
      "\n",
      "optional arguments:\n",
      "  --seed SEED           random number seed: use a nonnegative int for\n",
      "                        repeatable results (type: Int64, default: -1)\n",
      "  --batchsize BATCHSIZE\n",
      "                        minibatch size (type: Int64, default: 100)\n",
      "  --epochs EPOCHS       number of epochs for training (type: Int64,\n",
      "                        default: 10)\n",
      "  --hidden [HIDDEN...]  sizes of hidden layers, e.g. --hidden 128 64\n",
      "                        for a net with two hidden layers (type: Int64)\n",
      "  --lr LR               learning rate (type: Float64, default: 0.15)\n",
      "  --winit WINIT         w initialized with winit*randn() (type:\n",
      "                        Float64, default: 0.1)\n",
      "  --fast                skip loss printing for faster run\n",
      "  --atype ATYPE         array type: Array for cpu, KnetArray for gpu\n",
      "                        (default: \"KnetArray{Float32}\")\n",
      "  --gcheck GCHECK       check N random gradients per parameter (type:\n",
      "                        Int64, default: 0)\n",
      "  --dropout DROPOUT     Dropout probability. (type: Float64, default:\n",
      "                        0.5)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FashionMNIST.main(\"--help\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fashion-mnist.jl (c) 2017 Adapted by Emre Unal based on Deniz Yuret’s MNIST example https://github.com/denizyuret/Knet.jl/tree/master/examples/mnist-mlp/mlp.jl.\n",
      "Multi-layer perceptron model on the Fashion-MNIST dataset from https://github.com/zalandoresearch/fashion-mnist.\n",
      "\n",
      "opts=(:batchsize, 100)(:fast, false)(:atype, \"KnetArray{Float32}\")(:epochs, 10)(:gcheck, 0)(:winit, 0.1)(:dropout, 0.5)(:lr, 0.15)(:hidden, Int64[])(:seed, -1)\n",
      "(:epoch, 0, :trn, 0.12296666666666667, :tst, 0.1225)\n",
      "(:epoch, 1, :trn, 0.8116, :tst, 0.8001)\n",
      "(:epoch, 2, :trn, 0.8321166666666666, :tst, 0.8175)\n",
      "(:epoch, 3, :trn, 0.84125, :tst, 0.8256)\n",
      "(:epoch, 4, :trn, 0.8467666666666667, :tst, 0.8295)\n",
      "(:epoch, 5, :trn, 0.8503833333333334, :tst, 0.834)\n",
      "(:epoch, 6, :trn, 0.8528666666666667, :tst, 0.836)\n",
      "(:epoch, 7, :trn, 0.8554, :tst, 0.8365)\n",
      "(:epoch, 8, :trn, 0.8572833333333333, :tst, 0.8375)\n",
      "(:epoch, 9, :trn, 0.8585166666666667, :tst, 0.8378)\n",
      "(:epoch, 10, :trn, 0.8599333333333333, :tst, 0.8391)\n",
      "  7.857764 seconds (8.35 M allocations: 4.264 GiB, 5.97% gc time)\n"
     ]
    }
   ],
   "source": [
    "model = FashionMNIST.main(\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
