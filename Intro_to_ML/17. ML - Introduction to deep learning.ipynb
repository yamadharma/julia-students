{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нейросети глубокого обучения\n",
    "\n",
    "Мы узнали, что если хочется классифицировать более двух объектов, нам нужно выйти за рамки использования одного нейрона и использовать *несколько* нейронов для получения нескольких выходов. Мы можем думать об объединении этих нескольких нейронов в один нейронный слой.\n",
    "\n",
    "Несмотря на это, мы обнаружили, что использование одного нейронного слоя недостаточно для того, чтобы полностью различить бананы, виноград и яблоки. Чтобы сделать это правильно, нам нужно добавить больше сложности к нашей модели. Нам нужна не просто нейронная сеть, а *глубокая нейронная сеть*. \n",
    "\n",
    "Осталось сделать еще один шаг, чтобы построить глубокую нейронную сеть. Мы говорили, что нейронная сеть принимает данные, а затем выплевывает прогнозы «0» или «1», которые вместе объявляют, какой плод представляет собой картинка. Однако что, если мы вместо этого поместим выходные данные одного слоя нейронной сети в другой слой нейронной сети? Это изображено ниже:\n",
    "\n",
    "<img src=\"data/deep-neural-net.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "Слева у нас есть 3 точки данных синим цветом. Эти донные поступают в 4 нейрона фиолетового цвета. Каждый из этих 4 нейронов производит один выход, но каждый из этих выходов подается в три нейрона (второй слой пурпурного цвета). Каждый из этих 3 нейронов выделяет одно значение, и эти значения вводятся в качестве входных данных в последний слой из 6 нейронов. 6 значений, которые производят эти конечные нейроны, являются выходом нейронной сети. Это глубокая нейронная сеть."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Почему глубокая нейронная сеть была бы лучше?\n",
    "\n",
    "Это немного сбивает с толку, когда вы впервые видите это. Раньше мы использовали нейроны для обучения модели: почему вставка выходных данных из нейронов в другие нейроны помогает нам лучше соответствовать данным? Ответ можно понять по рисунку. Геометрически, умножение матрицы внутри слоя нейронов растягивает и вращает ось, которую мы можем варьировать:\n",
    "\n",
    ">[Show linear transformation of axis, with data]\n",
    "\n",
    "Нелинейное преобразование, такое как функция сигмоида, затем добавляет удар к строке:\n",
    "\n",
    ">[Show the linear transformed axis with data, and then a bumped version that fits the data better]\n",
    "\n",
    "Теперь давайте повторим этот процесс. Когда мы отправляем данные через другой слой нейронов, мы получаем еще один поворот и еще один удар:\n",
    "\n",
    ">[Show another rotation, then another bump]\n",
    "\n",
    "Визуально мы видим, что если мы продолжим этот процесс, мы сможем выровнять ось с любыми данными. Это означает, что **если у нас достаточно слоев, то наша нейронная сеть может приблизиться к любой модели**. \n",
    "\n",
    "Компромисс состоит в том, что при большем количестве слоев у нас больше параметров, что делает обучение более многогранным. \n",
    "\n",
    "Поскольку эта модель очень гибкая, проблема сводится к проблеме обучения: применим тот же метод градиентного спуска к этой гораздо большей модели (но более эффективной!), и мы сможем заставить ее правильно классифицировать наши данные. Это сила глубокого обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
